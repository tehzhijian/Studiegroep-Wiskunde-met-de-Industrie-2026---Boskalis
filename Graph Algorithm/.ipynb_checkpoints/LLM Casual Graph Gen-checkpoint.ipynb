{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f3072b-4c23-4408-bee4-d79799843b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "WARNING: Running an LLM on CPU will be very slow. A GPU is highly recommended.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import  transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from builder import CausalGraphBuilder  # Imports the class from your uploaded builder.py\n",
    "\n",
    "# Configure logging to see progress\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check for GPU (Strongly recommended for LLMs)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cpu\":\n",
    "    print(\"WARNING: Running an LLM on CPU will be very slow. A GPU is highly recommended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed7c377-643f-4077-a708-8717a319a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "class OpenRouterLLM:\n",
    "    def __init__(self, \n",
    "                 model: str = \"deepseek/deepseek-r1:free\", \n",
    "                 api_key: str = None, \n",
    "                 site_url: str = None, \n",
    "                 app_name: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the OpenRouter/DeepSeek client.\n",
    "        \n",
    "        Args:\n",
    "            model: The OpenRouter model ID (default: deepseek/deepseek-r1:free)\n",
    "            api_key: Your OpenRouter API key. If None, looks for OPENROUTER_API_KEY env var.\n",
    "        \"\"\"\n",
    "        # Initialize the client pointing to OpenRouter\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=api_key or os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "        )\n",
    "        self.model = model\n",
    "        \n",
    "        # Optional headers required by OpenRouter for rankings\n",
    "        self.extra_headers = {}\n",
    "        if site_url:\n",
    "            self.extra_headers[\"HTTP-Referer\"] = site_url\n",
    "        if app_name:\n",
    "            self.extra_headers[\"X-Title\"] = app_name\n",
    "\n",
    "    def generate(self, prompt: str, temperature: float = 0.1, json_mode: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Generates text based on the prompt using OpenRouter. \n",
    "        Matches the signature required by builder.py.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prepare messages\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a specialized assistant that extracts causal graphs. You answer strictly in JSON.\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "\n",
    "            # Make the API call\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                extra_headers=self.extra_headers,\n",
    "                temperature=temperature,\n",
    "                # Note: 'json_object' mode ensures valid JSON, but not all free models support it.\n",
    "                # If the specific DeepSeek model supports it, uncomment the line below:\n",
    "                # response_format={\"type\": \"json_object\"} if json_mode else None\n",
    "            )\n",
    "\n",
    "            response_content = completion.choices[0].message.content\n",
    "\n",
    "            # --- DEEPSEEK R1 SPECIFIC CLEANING ---\n",
    "            # DeepSeek R1 often includes \"Chain of Thought\" reasoning inside <think> tags.\n",
    "            # We must remove this, otherwise the JSON parser in builder.py will fail.\n",
    "            cleaned_content = re.sub(r'<think>.*?</think>', '', response_content, flags=re.DOTALL).strip()\n",
    "            \n",
    "            return cleaned_content\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating with OpenRouter: {e}\")\n",
    "            return \"[]\"  # Return empty JSON array on failure to prevent crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b485dd-cff2-45cb-a778-00aa922f5546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 2041 documents.\n",
      "Preview (first 200 chars): A triangle is a polygon with three corners and three sides, one of the basic shapes in geometry. The corners, also called vertices, are zero-dimensional points while the sides connecting them, also ca...\n"
     ]
    }
   ],
   "source": [
    "input_file = \"wiki_math_knowledge_base_api.json\"\n",
    "\n",
    "try:\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract just the raw text content for the builder\n",
    "    # The builder expects a list of strings\n",
    "    documents = [item.get(\"raw_text\", \"\") for item in data if item.get(\"raw_text\")]\n",
    "\n",
    "    print(f\"Successfully loaded {len(documents)} documents.\")\n",
    "    # Preview the first document\n",
    "    print(f\"Preview (first 200 chars): {documents[0][:200]}...\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find '{input_file}'. Please make sure it is in the same folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad00a61-9f83-476b-8d86-8b2626582955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CausalGraphBuilder\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Initialize the interface\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Make sure you have set os.environ[\"OPENROUTER_API_KEY\"] or pass the key directly\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m llm = \u001b[43mOpenRouterLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# <--- FIXED: Added missing comma here\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek/deepseek-r1-distill-llama-70b:free\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Pass it to the builder\u001b[39;00m\n\u001b[32m     11\u001b[39m builder = CausalGraphBuilder(\n\u001b[32m     12\u001b[39m     extractor_method=\u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     13\u001b[39m     llm_interface=llm\n\u001b[32m     14\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mOpenRouterLLM.__init__\u001b[39m\u001b[34m(self, model, api_key, site_url, app_name)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03mInitialize the OpenRouter/DeepSeek client.\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m    api_key: Your OpenRouter API key. If None, looks for OPENROUTER_API_KEY env var.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Initialize the client pointing to OpenRouter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://openrouter.ai/api/v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENROUTER_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Optional headers required by OpenRouter for rankings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\SWI2026\\Lib\\site-packages\\openai\\_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from builder import CausalGraphBuilder\n",
    "\n",
    "# 1. Initialize the interface\n",
    "# Make sure you have set os.environ[\"OPENROUTER_API_KEY\"] or pass the key directly\n",
    "llm = OpenRouterLLM(\n",
    "    api_key=\"\",  # <--- FIXED: Added missing comma here\n",
    "    model=\"deepseek/deepseek-r1-distill-llama-70b:free\" \n",
    ")\n",
    "\n",
    "# 2. Pass it to the builder\n",
    "builder = CausalGraphBuilder(\n",
    "    extractor_method=\"llm\", \n",
    "    llm_interface=llm\n",
    ")\n",
    "\n",
    "# 3. Process your text\n",
    "# FIXED: You previously passed '[input_file]' (the filename string). \n",
    "# You must pass 'documents', which is the list of text strings you loaded in Cell 4.\n",
    "# We slice [:5] to test first, so you don't hit Rate Limits (429) immediately.\n",
    "print(f\"Processing 5 out of {len(documents)} documents for testing...\")\n",
    "builder.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5b6c7-c1e8-4df4-be63-3fc831ea4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save internal JSON format\n",
    "builder.save(\"causal_math_graph_llm_2.json\")\n",
    "\n",
    "# 2. Export to GraphML (Standard format for network analysis tools)\n",
    "G = builder.get_graph()\n",
    "nx.write_graphml(G, \"causal_math_graph_llm_2.graphml\")\n",
    "\n",
    "print(\"Files saved: 'causal_math_graph_llm_2.json' and 'causal_math_graph_llm.graphml'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08060f15-01a8-4978-a366-91823beaca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interactive HTML visualization\n",
    "html_path = builder.visualize_graph(\n",
    "    output_path=\"llm_graph_viz.html\",\n",
    "    format=\"html\",\n",
    "    title=\"Math Knowledge Graph (LLM Generated)\"\n",
    ")\n",
    "print(f\"Interactive visualization saved to: {html_path}\")\n",
    "\n",
    "# Display static plot in notebook\n",
    "plt.figure(figsize=(15, 15))\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20, seed=42)\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100, node_color='skyblue', alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.3, arrows=True)\n",
    "\n",
    "# Draw labels for top nodes (to avoid clutter)\n",
    "# Only label nodes with high degree\n",
    "degrees = dict(G.degree())\n",
    "top_nodes = {n for n, d in degrees.items() if d > 1}\n",
    "labels = {n: n for n in top_nodes}\n",
    "\n",
    "nx.draw_networkx_labels(G, pos, labels=labels, font_size=8, font_color='black')\n",
    "\n",
    "plt.title(\"Causal Graph Preview (LLM Extracted)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd3a58-d8fa-40e5-a2a3-ff40b125ad86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
